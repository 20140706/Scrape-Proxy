#!/usr/bin/env python3
"""
GitHub Actions SOCKS5ä»£ç†æµ‹è¯•å·¥å…· - å¤šçº¿ç¨‹å®Œæ•´ç‰ˆ
ä¿®å¤ç‰ˆï¼šæ­£ç¡®çš„SOCKS5ä»£ç†éªŒè¯
"""

import requests
import random
import sys
import time
from datetime import datetime
import json
import logging
import ipaddress
from concurrent.futures import ThreadPoolExecutor, as_completed


# å°è¯•å®‰è£…å¿…è¦çš„åº“
def install_dependencies():
    try:
        import socket
        return True
    except ImportError:
        return False


# é…ç½®æ—¥å¿—
def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('proxy_test.log', encoding='utf-8')
        ]
    )
    return logging.getLogger(__name__)


logger = setup_logging()

# å…¨å±€å˜é‡ï¼šæœ¬æœºçœŸå®å…¬ç½‘ IP
REAL_IP = None


def get_real_ip():
    """è·å–æœ¬æœºçœŸå®å…¬ç½‘ IPï¼ˆç”¨äºå¯¹æ¯”éªŒè¯ï¼‰"""
    global REAL_IP
    if REAL_IP is not None:
        return REAL_IP
    try:
        resp = requests.get("https://icanhazip.com", timeout=10)
        ip = resp.text.strip()
        if is_valid_ipv4(ip):
            REAL_IP = ip
            logger.info(f"æœ¬æœºçœŸå®å…¬ç½‘ IP: {REAL_IP}")
            return REAL_IP
        else:
            logger.error("å“åº”å†…å®¹ä¸æ˜¯æœ‰æ•ˆ IPv4 åœ°å€")
            return None
    except Exception as e:
        logger.error(f"è·å–æœ¬æœºå…¬ç½‘ IP å¤±è´¥: {e}")
        return None


def is_valid_ipv4(ip_str):
    """ä¸¥æ ¼æ ¡éªŒ IPv4 åœ°å€"""
    try:
        ipaddress.IPv4Address(ip_str)
        return True
    except ipaddress.AddressValueError:
        return False


# ä»£ç†æ¥æºåˆ—è¡¨
PROXY_SOURCES = [
    "https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/socks5.txt",
    "https://raw.githubusercontent.com/monosans/proxy-list/main/proxies_anonymous/socks5.txt",
    "https://raw.githubusercontent.com/ErcinDedeoglu/proxies/main/proxies/socks5.txt",
    "https://raw.githubusercontent.com/Zaeem20/FREE_PROXIES_LIST/master/socks5.txt"
]

# æµ‹è¯•ç½‘ç«™
TEST_WEBSITE = "https://icanhazip.com"

# User-Agentåˆ—è¡¨
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
]


def get_user_agent():
    """è·å–éšæœºUser-Agent"""
    return random.choice(USER_AGENTS)


def parse_proxy(proxy_str):
    """è§£æä»£ç†å­—ç¬¦ä¸²ï¼Œæ”¯æŒæ ¼å¼: ip:port æˆ– user:pass@ip:port"""
    proxy_str = proxy_str.strip()

    # ç§»é™¤å¯èƒ½çš„åè®®å‰ç¼€
    for prefix in ['socks5://', 'socks4://', 'http://', 'https://']:
        if proxy_str.startswith(prefix):
            proxy_str = proxy_str[len(prefix):]

    # åˆ†ç¦»è®¤è¯ä¿¡æ¯å’Œä¸»æœºä¿¡æ¯
    if '@' in proxy_str:
        auth_part, host_part = proxy_str.split('@', 1)
        if ':' in auth_part:
            username, password = auth_part.split(':', 1)
        else:
            username, password = auth_part, None
    else:
        username, password = None, None
        host_part = proxy_str

    # è§£æä¸»æœºå’Œç«¯å£
    if ':' in host_part:
        host, port_str = host_part.rsplit(':', 1)
        try:
            port = int(port_str)
        except ValueError:
            port = 1080
    else:
        host, port = host_part, 1080

    return {
        'host': host.strip(),
        'port': port,
        'username': username,
        'password': password,
        'original': proxy_str.strip()
    }


def test_single_proxy(proxy_str, timeout=8, real_ip=None):
    """æµ‹è¯•å•ä¸ªSOCKS5ä»£ç†"""
    try:
        # è§£æä»£ç†
        proxy_info = parse_proxy(proxy_str)

        # æ„é€ ä»£ç†å­—å…¸
        proxy_url = f"socks5://{proxy_info['original']}"

        # è®¾ç½®ä»£ç†
        proxies = {
            'http': proxy_url,
            'https': proxy_url
        }

        # ä½¿ç”¨ä»£ç†æµ‹è¯•è¿æ¥
        start_time = time.time()
        response = requests.get(
            TEST_WEBSITE,
            proxies=proxies,
            timeout=timeout,
            headers={'User-Agent': get_user_agent()},
            allow_redirects=False
        )
        latency = time.time() - start_time

        if response.status_code == 200:
            ip = response.text.strip()

            # éªŒè¯IPæ ¼å¼
            if not is_valid_ipv4(ip):
                logger.debug(f"ä»£ç† {proxy_str} è¿”å›æ— æ•ˆIPæ ¼å¼: {repr(ip)}")
                return None

            # æ£€æŸ¥æ˜¯å¦ä¸çœŸå®IPç›¸åŒ
            if real_ip and ip == real_ip:
                logger.debug(f"ä»£ç† {proxy_str} è¿”å›ä¸æœ¬æœºç›¸åŒçš„IP ({ip})ï¼Œåˆ¤å®šæ— æ•ˆ")
                return None

            logger.debug(f"âœ“ ä»£ç† {proxy_str} æµ‹è¯•æˆåŠŸ: {ip} (å»¶è¿Ÿ: {latency:.2f}s)")

            return {
                'proxy': proxy_str,
                'ip': ip,
                'avg_latency': round(latency, 2),
                'results': [{
                    'website': TEST_WEBSITE,
                    'status_code': 200,
                    'response': ip,
                    'latency': round(latency, 2)
                }],
                'success': True
            }
        else:
            logger.debug(f"ä»£ç† {proxy_str} è¿”å›çŠ¶æ€ç : {response.status_code}")

    except requests.exceptions.ConnectTimeout:
        logger.debug(f"ä»£ç† {proxy_str} è¿æ¥è¶…æ—¶")
    except requests.exceptions.ReadTimeout:
        logger.debug(f"ä»£ç† {proxy_str} è¯»å–è¶…æ—¶")
    except requests.exceptions.ConnectionError as e:
        logger.debug(f"ä»£ç† {proxy_str} è¿æ¥é”™è¯¯: {e}")
    except requests.exceptions.ProxyError as e:
        logger.debug(f"ä»£ç† {proxy_str} ä»£ç†é”™è¯¯: {e}")
    except Exception as e:
        logger.debug(f"ä»£ç† {proxy_str} æµ‹è¯•å¤±è´¥: {type(e).__name__}")

    return None


def test_proxies(proxy_list, real_ip=None, max_workers=500):
    """ä½¿ç”¨å¤šçº¿ç¨‹æµ‹è¯•æ‰€æœ‰ä»£ç†"""
    if not proxy_list:
        return []

    logger.info(f"å¯åŠ¨ {max_workers} ä¸ªçº¿ç¨‹ï¼Œå¼€å§‹æµ‹è¯•å…¨éƒ¨ {len(proxy_list)} ä¸ªä»£ç†...")
    random.shuffle(proxy_list)  # æ‰“ä¹±é¡ºåº

    working_proxies = []
    tested_count = 0

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_proxy = {executor.submit(test_single_proxy, proxy, 8, real_ip): proxy for proxy in proxy_list}

        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_proxy):
            tested_count += 1
            proxy = future_to_proxy[future]

            try:
                result = future.result(timeout=10)
                if result:
                    working_proxies.append(result)
                    logger.info(
                        f"âœ“ å¯ç”¨ä»£ç† [{len(working_proxies)}]: {result['proxy']} "
                        f"(å‡ºå£IP: {result['ip']}, å»¶è¿Ÿ: {result['avg_latency']}s)"
                    )
            except Exception as e:
                logger.debug(f"æµ‹è¯•ä»£ç† {proxy} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

            # æ¯å®Œæˆ10%æˆ–æ¯100ä¸ªæ‰“å°ä¸€æ¬¡è¿›åº¦
            if tested_count % 100 == 0 or tested_count == len(proxy_list):
                logger.info(
                    f"è¿›åº¦: å·²æµ‹è¯• {tested_count}/{len(proxy_list)} ä¸ªä»£ç†ï¼Œæ‰¾åˆ° {len(working_proxies)} ä¸ªå¯ç”¨ä»£ç†")

    logger.info(f"âœ… å¤šçº¿ç¨‹æµ‹è¯•å®Œæˆï¼å…±æ‰¾åˆ° {len(working_proxies)} ä¸ªå¯ç”¨ä»£ç†")
    return working_proxies


def fetch_proxies():
    """ä»å¤šä¸ªæ¥æºè·å–ä»£ç†"""
    all_proxies = set()
    failed_sources = 0

    for url in PROXY_SOURCES:
        try:
            logger.info(f"æ­£åœ¨è·å–ä»£ç†: {url}")
            headers = {
                'User-Agent': get_user_agent(),
                'Accept': 'text/plain,text/html',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive'
            }

            response = requests.get(url, timeout=15, headers=headers)
            response.raise_for_status()

            # è§£æä»£ç†åˆ—è¡¨
            lines = response.text.strip().split('\n')
            valid_count = 0

            for line in lines:
                line = line.strip()
                if not line or line.startswith(('#', '//', '/*', '*/', '--')):
                    continue

                # ç®€å•æ ¼å¼éªŒè¯
                if ':' in line and '.' in line.split(':')[0]:
                    all_proxies.add(line)
                    valid_count += 1

            logger.info(f"ä» {url} è·å–åˆ° {valid_count} ä¸ªä»£ç†")

        except requests.exceptions.Timeout:
            logger.warning(f"è·å– {url} è¶…æ—¶")
            failed_sources += 1
        except requests.exceptions.RequestException as e:
            logger.warning(f"è·å– {url} å¤±è´¥: {e}")
            failed_sources += 1
        except Exception as e:
            logger.warning(f"å¤„ç† {url} æ—¶å‡ºé”™: {e}")
            failed_sources += 1

    proxy_list = list(all_proxies)
    logger.info(f"æ€»å…±ä» {len(PROXY_SOURCES)} ä¸ªæºè·å–åˆ° {len(proxy_list)} ä¸ªå”¯ä¸€ä»£ç† ({failed_sources} ä¸ªæºå¤±è´¥)")

    return proxy_list


def save_results(working_proxies, total_proxies_fetched):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    # æŒ‰å»¶è¿Ÿæ’åº
    working_proxies.sort(key=lambda x: x['avg_latency'])

    # ä¿å­˜å®Œæ•´JSONç»“æœ
    json_data = {
        'timestamp': timestamp,
        'total_proxies_fetched': total_proxies_fetched,
        'working_proxies_count': len(working_proxies),
        'working_proxies': working_proxies
    }

    with open('proxy_results.json', 'w', encoding='utf-8') as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)

    # ä¿å­˜æ‰€æœ‰å¯ç”¨ä»£ç†
    with open('available_proxies.txt', 'w', encoding='utf-8') as f:
        for proxy_info in working_proxies:
            f.write(f"{proxy_info['proxy']}\n")

    # ä¿å­˜å‰20ä¸ªæœ€å¿«ä»£ç†
    with open('BEST_SOCKS5.txt', 'w', encoding='utf-8') as f:
        if working_proxies:
            for i, proxy_info in enumerate(working_proxies[:20], 1):
                f.write(f"{proxy_info['proxy']} | å»¶è¿Ÿ: {proxy_info['avg_latency']}ç§’ | IP: {proxy_info['ip']}\n")
        else:
            f.write("# æœªæ‰¾åˆ°å¯ç”¨ä»£ç†\n")

    logger.info("ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: available_proxies.txt, BEST_SOCKS5.txt, proxy_results.json")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ SOCKS5 ä»£ç†æµ‹è¯•ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰")

    start_time = time.time()

    # è·å–æœ¬æœºçœŸå®å…¬ç½‘ IP
    logger.info("æ­£åœ¨è·å–æœ¬æœºçœŸå®å…¬ç½‘IP...")
    real_ip = get_real_ip()
    if real_ip is None:
        logger.warning("âš ï¸ æ— æ³•è·å–æœ¬æœºå…¬ç½‘ IPï¼Œå°†è·³è¿‡ IP å¯¹æ¯”éªŒè¯ï¼ˆå¯èƒ½äº§ç”Ÿå‡é˜³æ€§ï¼‰")

    try:
        # 1. è·å–ä»£ç†åˆ—è¡¨
        logger.info("ğŸ“¡ æ­£åœ¨ä»å¤šä¸ªæ¥æºè·å–ä»£ç†...")
        all_proxies = fetch_proxies()

        if not all_proxies:
            logger.error("âŒ æœªèƒ½è·å–åˆ°ä»»ä½•ä»£ç†")
            save_results([], 0)
            return 0

        logger.info(f"ğŸ“Š è·å–åˆ° {len(all_proxies)} ä¸ªä»£ç†ï¼Œå¼€å§‹æµ‹è¯•...")

        # 2. å¤šçº¿ç¨‹æµ‹è¯•æ‰€æœ‰ä»£ç†
        logger.info("ğŸ§ª å¼€å§‹å¤šçº¿ç¨‹æµ‹è¯•æ‰€æœ‰ä»£ç†...")
        working_proxies = test_proxies(all_proxies, real_ip=real_ip, max_workers=500)

        # 3. ä¿å­˜ç»“æœ
        logger.info("ğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœ...")
        save_results(working_proxies, len(all_proxies))

        # 4. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        end_time = time.time()
        total_time = end_time - start_time

        print("\n" + "=" * 60)
        print("ğŸ¯ SOCKS5 ä»£ç†æµ‹è¯•å®Œæˆ")
        print("=" * 60)
        print(f"æ€»ä»£ç†æ•°: {len(all_proxies)}")
        print(f"å¯ç”¨ä»£ç†æ•°: {len(working_proxies)}")
        print(f"æµ‹è¯•è€—æ—¶: {total_time:.2f} ç§’")
        print(f"æˆåŠŸç‡: {(len(working_proxies) / max(1, len(all_proxies))) * 100:.2f}%")

        if working_proxies:
            print(f"\nğŸ† æœ€å¿«çš„å‰5ä¸ªä»£ç†:")
            for i, proxy in enumerate(working_proxies[:5], 1):
                print(f"{i:2d}. {proxy['proxy']}")
                print(f"    å‡ºå£IP: {proxy['ip']}")
                print(f"    å»¶è¿Ÿ: {proxy['avg_latency']}ç§’")
        else:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨ä»£ç†")

        print("=" * 60)
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("  - available_proxies.txt (æ‰€æœ‰å¯ç”¨ä»£ç†)")
        print("  - BEST_SOCKS5.txt (å‰20ä¸ªæœ€å¿«ä»£ç†)")
        print("  - proxy_results.json (å®Œæ•´JSONç»“æœ)")
        print("  - proxy_test.log (è¯¦ç»†æ—¥å¿—)")
        print("=" * 60)

        return 0

    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        logger.exception(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        save_results([], 0)
        return 1


if __name__ == "__main__":
    sys.exit(main())
